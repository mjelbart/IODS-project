# Chapter 3: Logistic Regression
## 2. The dataset
### A brief description of the dataset:
The dataset regards student achievement in secondary education of two Portuguese schools, collected by using school reports and questionnaires.
The data attributes include student grades, demographic, social and school related features. 
More on the two data sets (from which the alc dataset is composed) can be found at https://archive.ics.uci.edu/ml/datasets/Student+Performance

Data wrangling notes

* Data from students of two subjects have been joined.
* The variables not used for correlating the two data have been combined by averaging.
* The variable 'alc_use' (alcohol use) is the average of 'Dalc' and 'Walc' (Daily alcohol consumption and Weekly alcohol consumption).
* The variable 'high_use' is TRUE if 'alc_use' is higher than 2 and FALSE otherwise.


See the variables (column names) listed below:
```{r}


# Read the joined student alcohol consumption data into R
alc <- read.table("data/alc.txt", header = TRUE, sep=",")

# Print out the names of the variables in the data
colnames(alc)
str(alc)


```




## 3. In order to study the relationships between high/low alcohol consumption and some of the other variables in the data I will choose four interesting variables and present my hypotheses about their relationship with alcohol consumption.  
### My hypotheses

1. Males: Alcohol useage will be higher for males.
2. Free time: Alcohol usage will be higher for students with more free time.
3. Failures: Alcohol usage will be higher for students with more failures.
4. Absences: Students with higher alcohol usage will have more absences.



##4. A numerical and graphical exploration of the distributions of my chosen variables and their relationships with alcohol consumption.
For a numerical exploration I will look at the odds ratio. The probabilty that alcohol usage is high given X variable is present divided by the probabiliy of alcohol usage being low when X variable is present. All that divided by the opposite. gives a number or a fraction and that tells you how likely it is that when you have X you have high alcohol usage. 

cross-tabulations, 
bar plots 
box plots

```{r}
library(tidyr); library(dplyr); library(ggplot2) 
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()

```

### Comments on my findings and comparisons of the results of my exploration to my previously stated hypotheses.

I found that.....

In relation to my hypotheses

1. Males: 
2. Parents apart: 
3. Failures: 
4. Absences: 



## 5. Using logistic regression to statistically explore the relationship between my chosen variables and the binary high/low alcohol consumption target variable. 
```{r}
model <- glm(high_use ~ sex + romantic + failures + absences, data = alc, family = "binomial")

model

```

### Presentation and interpretation of a summary of the fitted model. 
```{r}
summary(model)

```

### Presentation and interpretation of the coefficients of the model as odds ratios and confidence intervals for them.
SexM, Failures and Absences all have an odds ratio over 1. This indicates that each of them are positively associated with alcohol use. Students with high alcohol use were more often male than female, failed more those with low alcohol use, and were absent more often than student with low alcohol use.

```{r}
oddsratios <- coef(model) %>% exp

confidenceintervals <- confint(model) %>% exp

cbind(oddsratios, confidenceintervals)

```


### Interpret the results and compare them to your previously stated hypothesis. Hint: If your model includes factor variables see for example the first answer of this stackexchange thread <http://stats.stackexchange.com/questions/60817/significance-of-categorical-predictor-in-logistic-regression> on how R treats and how you should interpret these variables in the model output (or use some other resource to study this). (0-5 points)


## 6. According to my logistic regression model, the variables that had a statistical relationship with high/low alcohol consumption are: 

### Using these explore the predictive power of you model.
"When you have a linear model, you can make predictions. A very basic question is, of course, how well does our model actually predict the target variable."
```{r}
# predict() the probability of high_use and add the predicted probabilities to the 'alc' data set
probabilities <- predict(model, type = "response")
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = "change me!")

# use the probabilities to make a prediction of high_use. Mutate the data again: add a column 'prediction' which is true if the value of 'probability' is greater than 0.5.
alc <- mutate(alc, prediction = probabilities > 0.5)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, failures, absences, sex, high_use, probability, prediction) %>% tail(10)
```

### Provide a 2x2 cross tabulation of predictions versus the actual values and optionally display a graphic visualizing both the actual values and the predictions. 

```{r}
# tabulate the target variable versus the predictions. Use table() to create a cross table of the columns 'high_use' versus 'prediction' in alc. This is sometimes called a 'confusion matrix`.
table(high_use = alc$high_use, prediction = alc$prediction)

table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table() %>% addmargins()
```

### Computation of the total proportion of inaccurately classified individuals (= the training error) and comments on all the results. 
The proportion of inaccurately classified observations can be obtained by a loss function. 

###Compare the performance of the model with performance achieved by some simple guessing strategy. 



## 7. Bonus: Perform 10-fold cross-validation on your model. Does your model have better test set performance (smaller prediction error using 10-fold cross-validation) compared to the model introduced in DataCamp (which had about 0.26 error). Could you find such a model? (0-2 points to compensate any loss of points from the above exercises)
```{r}
# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(alc$high_use, alc$probability)

library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = model, K = 10)
cv$delta[1]
```

## 8. Super-Bonus: Perform cross-validation to compare the performance of different logistic regression models (= different sets of predictors). Start with a very high number of predictors and explore the changes in the training and testing errors as you move to models with less predictors. Draw a graph displaying the trends of both training and testing errors by the number of predictors in the model. (0-4 points to compensate any loss of points from the above exercises)