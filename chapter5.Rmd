# Chapter 5: Dimensionality reduction techniques

# Data Wrangling
I did the Data Wrangling for week 5 in the file data/create_human.R part way down the file with a comment saying '# Week 5 data wrangling'

Dataset Description: 
"The 'human' dataset originates from the United Nations Development Programme." -  http://hdr.undp.org/en/content/human-development-index-hdi - and includes 195 Observations of 19 Variables. See the Meta data file for the modified data at - https://raw.githubusercontent.com/TuomoNieminen/Helsinki-Open-Data-Science/master/datasets/human_meta.txt

```{r}
human <- read.csv("data/human3.txt", sep = ",")
dim(human)
str(human)
```


## 1. Description and interpretation of the data
The dataset combines several indicators (as variables) from most countries in the world. The variables are:

"Edu2.FM" = Proportion of females with at least secondary education / Proportion of males with at least secondary education

"Labo.FM" = Proportion of females in the labour force / Proportion of males in the labour force

"Edu.Exp" = Expected years of schooling 

"Life.Exp" = Life expectancy at birth

"GNI" = Gross National Income per capita

"Mat.Mor" = Maternal mortality ratio

"Ado.Birth" = Adolescent birth rate

"Parli.F" = Percetange of female representatives in parliament


### Summaries and a graphical overview of the data 
From the plot below we can see a number of correlations:

Countries with higher life expectancy have higher GNI, more expected years of schooling, higher rates of females with secondary education, less births to adolescent parents and less mothers dying in childbirth.

Mat.Mor and Ado.Birth positively correlated with each other and negatively correlated with Edu2.FM, Labo.FM, Edu.Exp, Life.Exp, GNI.

Notably from the distributions and variable summaries, the Female to Male secondary education ratio peaks close to 0.9. the majority of countries have a low GNI and low maternal mortality rate.


```{r}
library(ggplot2)
library(GGally)

summary(human)

ggpairs(human)
```





## 2. PCA 
Below we perform Principal component Analysis (PCA) on the non-standardized human data followed by a biplot displaying the observations by the first two principal components (PC1 coordinate in x-axis, PC2 coordinate in y-axis), along with arrows representing the original variables. 

What we're looking for with PCA is to reveal a small number of principal components that provide a reasonable characterization of the complete dataset. In the PCA below PC1 captures the maximum amount of variance from the features in the original data with a standard deviation of 1.85e+04 and PC2 captures the maximum amount of variability left with a standard deviation of 1.85e+02. Each of the principal components are less important than the one before in terms of captured variance.

In this case we can see from the Proportion of Variance that 99.9% of the variance is captured by PC1.

```{r}
# Principal Component Analysis with the Singular Value Decomposition method
pca_human <- prcomp(human)
summary(pca_human)

biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col = c("grey40", "deeppink2"))
```


## 3. PCA with Standardized variables
Below we repeat the above analysis but after standardizing the variables in the human data.

The results are quite different to the PCA with non-standardized variables. The GNI in the non-standardized dataset has values ranging from over one hundred thousand down to five hundred whereas the next largest range in another variable is much lower, from 0.6 to 204.8. This makes variance in any other variable seem inconsequential. PCA is sensitive to the scaling of the features and assumes that features with larger variance are more important than features with smaller variance.

In this new analysis PC1 captures 53.6% of the variance and PC2 captures 16.2% which is 69.8% combined, much less than for the PCA in section 2.

The small angle between several of the arrows indicates high positive correlation between their features. Mat.Mor with Ado.Birth; Parli.F with Labo.FM; and between Edu.Exp, Life.Exp, GNI and Edu2.FM


```{r}
# standardizing the variables
human_std <- scale(human)

# Principal Component Analysis with the Singular Value Decomposition method and a summary
pca_human <- prcomp(human_std)
s <- summary(pca_human)
s

# Draw a biplot displaying the observations by the first two principal components (PC1 coordinate in x-axis, PC2 coordinate in y-axis), along with arrows representing the original variables.
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col = c("grey40", "deeppink2"))

```

## 4. Interpretations
PC1 is highly positively correlated with Mat.Mor and Ado.Birth, shown in the biplot by the small angle between the arrows of those two features and the X-axis.

PC2 is highly positively correlated with Labo.FM and Parli.F.

So we can say that the highest variability between countries in this data set relates to adolecents giving birth and mothers dying in childbirth. Secondly that a significant but lesser variation between countries relates to women entering the labour force and parliment. PC1 and PC2 only cover 69.8% of the variance which means that there is significant variance in other components.


## 5. MCA on tea data

### 5a. The tea dataset
Loading the tea dataset from the package Factominer and a brief exploration. 
```{r}
# loading FactoMineR and the tea dataset
library(FactoMineR)
data(tea)

# Exploring the data
dim(tea)
str(tea)

# Visualising the data
library(ggplot2)
library(dplyr)
library(tidyr)
# ggplot2, dplyr and tidyr are available ***********************************
 
 
# visualizing the dataset. 
gather(tea) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) 
```
```{r}
# 36 variables is too much to see anything in this kind of visualisation. Let's reduce it to a few variables of interest.

# defining columns to keep in the dataset
keep_columns <- c("Tea", "How", "price", "sugar", "where", "home")
 
# select the 'keep_columns' to create a new dataset
tea_time <- dplyr::select(tea, one_of(keep_columns))
 
# look at the summaries and structure of the data
summary(tea_time)
str(tea_time)

# visualisation of the dataset with fewer variables
gather(tea_time) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) 

```

### 5b. MCA
Multiple Correspondence Analysis on six columns of the tea data.

With the numbers listed under categorical variables below, a value close to 1 indicates a strong link between the variable and dimension. The highest values are 0.643 for price in relation to Dimension 1 and where in relation to dimensions 1 and two with 0.636 and 0.567 respectively.

We can see from their proximity in the plot that having lemon with your tea is most often associated with the tea being black.

```{r}
# multiple correspondence analysis. 
mca <- MCA(tea_time, graph = FALSE)
 
# summary of the model
summary(mca)
 
# visualize MCA. 
plot(mca, invisible=c("ind"), habillage = "quali")



```


Biplot
```{r}
# create and print out a summary of mca
mca_summary <- summary(mca)
mca_summary
 
# rounded percetanges of variance captured by each PC
mca_pr <- round(1*mca_summary$importance[2, ], digits = 1)
 
# print out the percentages of variance
mca_pr
 
# create object pc_lab to be used as axis labels
pc_labels <- paste0(names(mca_pr), " (", mca_pr, "%)")
 
 


```

attempt to draw a biplot with the following did not work out - error in nrow(y) - 

# draw a biplot
biplot(mca_summary, cex = c(0.8, 1), col = c("grey40", "deeppink2"), xlab = pc_labels[1], ylab = pc_labels[2])
